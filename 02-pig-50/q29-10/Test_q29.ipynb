{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The bigdata extension is already loaded. To reload it, use:\n",
      "  %reload_ext bigdata\n",
      "put: `data.csv': File exists\n",
      "Found 3 items\n",
      "-rw-r--r--   1 root supergroup        632 2020-03-04 02:51 data.csv\n",
      "-rw-r--r--   1 root supergroup         84 2020-03-04 03:43 meses.txt\n",
      "drwxr-xr-x   - root supergroup          0 2020-03-04 03:29 output\n"
     ]
    }
   ],
   "source": [
    "########################################################################################################\n",
    "## Ejecución de Pig en Jupyter\n",
    "##    A continuación se describe como ejecutar comandos de Pig en Jupyter usando la extensión de Jupyter bigdata.\n",
    "%load_ext bigdata\n",
    "%pig_start\n",
    "%timeout 300\n",
    "## WordCount en Apache Pig\n",
    "##   Se cargan los archivos en Apache Pig.\n",
    "!hadoop fs -put *.csv .\n",
    "!hadoop fs -ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --\n",
      " -- Carga el archivo desde el disco duro\n",
      " --\n",
      " u = LOAD 'data.csv' USING PigStorage(',') \n",
      "    AS (id:int, \n",
      "        firstname:CHARARRAY, \n",
      "        surname:CHARARRAY, \n",
      "        birthday:CHARARRAY, \n",
      "        color:CHARARRAY, \n",
      "        quantity:INT);\n"
     ]
    }
   ],
   "source": [
    "%%pig\n",
    "--\n",
    "-- Carga el archivo desde el disco duro\n",
    "--\n",
    "u = LOAD 'data.csv' USING PigStorage(',') \n",
    "    AS (id:int, \n",
    "        firstname:CHARARRAY, \n",
    "        surname:CHARARRAY, \n",
    "        birthday:CHARARRAY, \n",
    "        color:CHARARRAY, \n",
    "        quantity:INT);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".*)',2) AS mes;GENERATE id, birthday, REGEX_EXTRACT(birthday, '(.*)-(.*)-( \n",
      " DUMP x;\n",
      "2020-03-04 03:52:24,271 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 03:52:24,444 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2020-03-04 03:52:24,448 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.compress is deprecated. Instead, use mapreduce.output.fileoutputformat.compress\n",
      "2020-03-04 03:52:24,459 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.submit.replication is deprecated. Instead, use mapreduce.client.submit.file.replication\n",
      "2020-03-04 03:52:24,841 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker.http.address is deprecated. Instead, use mapreduce.jobtracker.http.address\n",
      "2020-03-04 03:52:24,850 [JobControl] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 03:52:24,874 [JobControl] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
      "2020-03-04 03:52:24,957 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-03-04 03:52:24,982 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-03-04 03:52:25,039 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-03-04 03:52:25,157 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1583289929631_0041\n",
      "2020-03-04 03:52:25,334 [JobControl] INFO  org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.\n",
      "2020-03-04 03:52:25,400 [JobControl] INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1583289929631_0041\n",
      "2020-03-04 03:52:25,433 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://06626b12eba3:8088/proxy/application_1583289929631_0041/\n",
      "2020-03-04 03:52:40,552 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 03:52:40,557 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-04 03:52:40,700 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 03:52:40,704 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-04 03:52:40,734 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2020-03-04 03:52:40,736 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 03:52:40,740 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-04 03:52:40,799 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 03:52:40,803 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-04 03:52:40,833 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 03:52:40,837 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-04 03:52:40,863 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 03:52:40,867 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-04 03:52:40,921 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "(1,1971-07-08,07)\n",
      "(2,1974-05-23,05)\n",
      "(3,1973-04-22,04)\n",
      "(4,1975-01-29,01)\n",
      "(5,1974-07-03,07)\n",
      "(6,1974-10-18,10)\n",
      "(7,1970-10-05,10)\n",
      "(8,1969-02-24,02)\n",
      "(9,1974-10-17,10)\n",
      "(10,1975-02-28,02)\n",
      "(11,1969-12-07,12)\n",
      "(12,1973-12-24,12)\n",
      "(13,1970-08-27,08)\n",
      "(14,1972-12-12,12)\n",
      "(15,1970-07-01,07)\n",
      "(16,1974-02-11,02)\n",
      "(17,1973-04-01,04)\n",
      "(18,1973-04-29,04)\n"
     ]
    }
   ],
   "source": [
    "%%pig\n",
    "x = FOREACH u GENERATE id, birthday, REGEX_EXTRACT(birthday, '(.*)-(.*)-(.*)',2) AS mes;\n",
    "DUMP x;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " y = FOREACH x GENERATE id, birthday, mes, mes as (numMes:INT);\n",
      " DUMP y;\n",
      "2020-03-04 03:52:46,678 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 03:52:47,637 [JobControl] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 03:52:47,657 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-03-04 03:52:47,669 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-03-04 03:52:47,696 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-03-04 03:52:47,738 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1583289929631_0042\n",
      "2020-03-04 03:52:47,741 [JobControl] INFO  org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.\n",
      "2020-03-04 03:52:47,770 [JobControl] INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1583289929631_0042\n",
      "2020-03-04 03:52:47,780 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://06626b12eba3:8088/proxy/application_1583289929631_0042/\n",
      "2020-03-04 03:53:03,315 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 03:53:03,322 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-04 03:53:03,375 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 03:53:03,379 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-04 03:53:03,405 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 03:53:03,408 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-04 03:53:03,436 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 03:53:03,439 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-04 03:53:03,467 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 03:53:03,471 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-04 03:53:03,503 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 03:53:03,507 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-04 03:53:03,541 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "(1,1971-07-08,07,7)\n",
      "(2,1974-05-23,05,5)\n",
      "(3,1973-04-22,04,4)\n",
      "(4,1975-01-29,01,1)\n",
      "(5,1974-07-03,07,7)\n",
      "(6,1974-10-18,10,10)\n",
      "(7,1970-10-05,10,10)\n",
      "(8,1969-02-24,02,2)\n",
      "(9,1974-10-17,10,10)\n",
      "(10,1975-02-28,02,2)\n",
      "(11,1969-12-07,12,12)\n",
      "(12,1973-12-24,12,12)\n",
      "(13,1970-08-27,08,8)\n",
      "(14,1972-12-12,12,12)\n",
      "(15,1970-07-01,07,7)\n",
      "(16,1974-02-11,02,2)\n",
      "(17,1973-04-01,04,4)\n",
      "(18,1973-04-29,04,4)\n"
     ]
    }
   ],
   "source": [
    "%%pig\n",
    "y = FOREACH x GENERATE id, birthday, mes, mes as (numMes:INT);\n",
    "DUMP y;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting meses.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile meses.txt\n",
    "1\tjan\n",
    "2\tfeb\n",
    "3\tmar\n",
    "4\tapr\n",
    "5\tmay\n",
    "6\tjun\n",
    "7\tjul\n",
    "8\taug\n",
    "9\tsep\n",
    "10\toct\n",
    "11\tnov\n",
    "12\tdic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "put: `meses.txt': File exists\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -put meses.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " m = LOAD 'meses.txt' USING PigStorage()\n",
      "    AS (num_f:INT,\n",
      "        mes_f:CHARARRAY);\n"
     ]
    }
   ],
   "source": [
    "%%pig\n",
    "m = LOAD 'meses.txt' USING PigStorage()\n",
    "    AS (num_f:INT,\n",
    "        mes_f:CHARARRAY);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " DUMP r4;\n",
      "2020-03-04 03:56:20,059 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 03:56:20,591 [JobControl] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 03:56:20,600 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-03-04 03:56:20,607 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-03-04 03:56:20,611 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-03-04 03:56:20,637 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:2\n",
      "2020-03-04 03:56:20,654 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1583289929631_0049\n",
      "2020-03-04 03:56:20,657 [JobControl] INFO  org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.\n",
      "2020-03-04 03:56:20,699 [JobControl] INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1583289929631_0049\n",
      "2020-03-04 03:56:20,701 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://06626b12eba3:8088/proxy/application_1583289929631_0049/\n",
      "2020-03-04 03:56:41,202 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 03:56:41,208 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-04 03:56:41,275 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 03:56:41,278 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-04 03:56:41,299 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 03:56:41,301 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-04 03:56:41,322 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 03:56:41,324 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-04 03:56:41,347 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 03:56:41,349 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-04 03:56:41,370 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 03:56:41,373 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-04 03:56:41,400 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "(4,1975-01-29,jan,01,1)\n",
      "(10,1975-02-28,feb,02,2)\n",
      "(16,1974-02-11,feb,02,2)\n",
      "(8,1969-02-24,feb,02,2)\n",
      "(18,1973-04-29,apr,04,4)\n",
      "(17,1973-04-01,apr,04,4)\n",
      "(3,1973-04-22,apr,04,4)\n",
      "(2,1974-05-23,may,05,5)\n",
      "(1,1971-07-08,jul,07,7)\n",
      "(15,1970-07-01,jul,07,7)\n",
      "(5,1974-07-03,jul,07,7)\n",
      "(13,1970-08-27,aug,08,8)\n",
      "(7,1970-10-05,oct,10,10)\n",
      "(6,1974-10-18,oct,10,10)\n",
      "(9,1974-10-17,oct,10,10)\n",
      "(12,1973-12-24,dic,12,12)\n",
      "(14,1972-12-12,dic,12,12)\n",
      "(11,1969-12-07,dic,12,12)\n",
      " TempR4 = JOIN y BY numMes, m BY num_f;\n",
      "2020-03-04 03:58:20,693 [main] ERROR org.apache.pig.tools.grunt.Grunt - ERROR 1107: Cannot merge join keys, incompatible types. Outer: chararray; inner: int\n",
      "Details at logfile: /datalake/Talleres jumonsalve/evaluacion-final-juancamilo1203unal/02-pig-50/q29-10/pig_1583293935509.log\n",
      "T); = FOREACH TempR4 GENERATE id, birthday, mes_f, mes, mes as (numMes2:IN \n"
     ]
    }
   ],
   "source": [
    "%%pig\n",
    "TempR4 = JOIN y BY numMes, m BY num_f;\n",
    "r4 = FOREACH TempR4 GENERATE id, birthday, mes_f, mes, mes as (numMes2:INT);\n",
    "DUMP r4;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " DUMP r5;\n",
      "2020-03-04 04:02:40,270 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 04:02:40,753 [JobControl] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 04:02:40,764 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-03-04 04:02:40,771 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-03-04 04:02:40,773 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-03-04 04:02:40,794 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:2\n",
      "2020-03-04 04:02:40,808 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1583289929631_0057\n",
      "2020-03-04 04:02:40,811 [JobControl] INFO  org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.\n",
      "2020-03-04 04:02:40,832 [JobControl] INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1583289929631_0057\n",
      "2020-03-04 04:02:40,834 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://06626b12eba3:8088/proxy/application_1583289929631_0057/\n",
      "2020-03-04 04:03:00,854 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 04:03:00,861 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-04 04:03:00,906 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 04:03:00,911 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-04 04:03:00,930 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 04:03:00,931 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-04 04:03:01,038 [JobControl] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 04:03:01,045 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-03-04 04:03:01,052 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-03-04 04:03:01,478 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-03-04 04:03:01,493 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1583289929631_0058\n",
      "2020-03-04 04:03:01,496 [JobControl] INFO  org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.\n",
      "2020-03-04 04:03:01,516 [JobControl] INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1583289929631_0058\n",
      "2020-03-04 04:03:01,523 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://06626b12eba3:8088/proxy/application_1583289929631_0058/\n",
      "2020-03-04 04:03:27,066 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 04:03:27,074 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-04 04:03:27,124 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 04:03:27,127 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-04 04:03:27,150 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 04:03:27,152 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-04 04:03:27,657 [JobControl] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 04:03:27,666 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-03-04 04:03:27,676 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-03-04 04:03:28,100 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-03-04 04:03:28,117 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1583289929631_0059\n",
      "2020-03-04 04:03:28,124 [JobControl] INFO  org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.\n",
      "2020-03-04 04:03:28,145 [JobControl] INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1583289929631_0059\n",
      "2020-03-04 04:03:28,148 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://06626b12eba3:8088/proxy/application_1583289929631_0059/\n",
      "2020-03-04 04:03:53,280 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 04:03:53,289 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-04 04:03:53,338 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 04:03:53,341 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-04 04:03:53,361 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 04:03:53,363 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-04 04:03:53,393 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 04:03:53,395 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-04 04:03:53,428 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 04:03:53,429 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-04 04:03:53,448 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 04:03:53,452 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-04 04:03:53,476 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 04:03:53,478 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-04 04:03:53,502 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 04:03:53,504 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-04 04:03:53,524 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 04:03:53,526 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-04 04:03:53,544 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 04:03:53,545 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-04 04:03:53,563 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 04:03:53,567 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-04 04:03:53,595 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 04:03:53,597 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-04 04:03:53,634 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "(1,1971-07-08,jul,07,7)\n",
      "(2,1974-05-23,may,05,5)\n",
      "(3,1973-04-22,apr,04,4)\n",
      "(4,1975-01-29,jan,01,1)\n",
      "(5,1974-07-03,jul,07,7)\n",
      "(6,1974-10-18,oct,10,10)\n",
      "(7,1970-10-05,oct,10,10)\n",
      "(8,1969-02-24,feb,02,2)\n",
      "(9,1974-10-17,oct,10,10)\n",
      "(10,1975-02-28,feb,02,2)\n",
      "(11,1969-12-07,dic,12,12)\n",
      "(12,1973-12-24,dic,12,12)\n",
      "(13,1970-08-27,aug,08,8)\n",
      "(14,1972-12-12,dic,12,12)\n",
      "(15,1970-07-01,jul,07,7)\n",
      "(16,1974-02-11,feb,02,2)\n",
      "(17,1973-04-01,apr,04,4)\n",
      "(18,1973-04-29,apr,04,4)\n",
      " r5 = ORDER r4 BY id;\n"
     ]
    }
   ],
   "source": [
    "%%pig\n",
    "r5 = ORDER r4 BY id;\n",
    "DUMP r5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " DUMP r6;\n",
      "2020-03-04 04:05:03,957 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 04:05:04,545 [JobControl] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 04:05:04,553 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-03-04 04:05:04,560 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-03-04 04:05:04,563 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-03-04 04:05:04,993 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:2\n",
      "2020-03-04 04:05:05,009 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1583289929631_0063\n",
      "2020-03-04 04:05:05,011 [JobControl] INFO  org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.\n",
      "2020-03-04 04:05:05,032 [JobControl] INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1583289929631_0063\n",
      "2020-03-04 04:05:05,034 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://06626b12eba3:8088/proxy/application_1583289929631_0063/\n",
      "2020-03-04 04:05:30,181 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 04:05:30,187 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-04 04:05:30,237 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 04:05:30,241 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-04 04:05:30,259 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 04:05:30,261 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-04 04:05:30,764 [JobControl] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 04:05:30,773 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-03-04 04:05:30,780 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-03-04 04:05:30,801 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-03-04 04:05:30,821 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1583289929631_0064\n",
      "2020-03-04 04:05:30,824 [JobControl] INFO  org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.\n",
      "2020-03-04 04:05:30,844 [JobControl] INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1583289929631_0064\n",
      "2020-03-04 04:05:30,846 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://06626b12eba3:8088/proxy/application_1583289929631_0064/\n",
      "2020-03-04 04:05:50,872 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 04:05:50,878 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-04 04:05:50,928 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 04:05:50,931 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-04 04:05:50,956 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 04:05:50,958 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-04 04:05:51,050 [JobControl] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 04:05:51,061 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-03-04 04:05:51,069 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-03-04 04:05:51,093 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-03-04 04:05:51,510 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1583289929631_0065\n",
      "2020-03-04 04:05:51,512 [JobControl] INFO  org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.\n",
      "2020-03-04 04:05:51,732 [JobControl] INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1583289929631_0065\n",
      "2020-03-04 04:05:51,734 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://06626b12eba3:8088/proxy/application_1583289929631_0065/\n",
      "2020-03-04 04:06:11,824 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 04:06:11,829 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-04 04:06:11,879 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 04:06:11,883 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-04 04:06:11,901 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 04:06:11,906 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-04 04:06:11,935 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 04:06:11,937 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-04 04:06:11,959 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 04:06:11,961 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-04 04:06:11,981 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 04:06:11,983 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-04 04:06:12,002 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 04:06:12,004 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-04 04:06:12,021 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 04:06:12,022 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-04 04:06:12,042 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 04:06:12,043 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-04 04:06:12,074 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 04:06:12,075 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-04 04:06:12,097 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 04:06:12,106 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-04 04:06:12,129 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 04:06:12,131 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-04 04:06:12,157 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "(1971-07-08,jul,07,7)\n",
      "(1974-05-23,may,05,5)\n",
      "(1973-04-22,apr,04,4)\n",
      "(1975-01-29,jan,01,1)\n",
      "(1974-07-03,jul,07,7)\n",
      "(1974-10-18,oct,10,10)\n",
      "(1970-10-05,oct,10,10)\n",
      "(1969-02-24,feb,02,2)\n",
      "(1974-10-17,oct,10,10)\n",
      "(1975-02-28,feb,02,2)\n",
      "(1969-12-07,dic,12,12)\n",
      "(1973-12-24,dic,12,12)\n",
      "(1970-08-27,aug,08,8)\n",
      "(1972-12-12,dic,12,12)\n",
      "(1970-07-01,jul,07,7)\n",
      "(1974-02-11,feb,02,2)\n",
      "(1973-04-01,apr,04,4)\n",
      "(1973-04-29,apr,04,4)\n",
      " r6 = FOREACH r5 GENERATE birthday, mes_f, mes, numMes2;\n"
     ]
    }
   ],
   "source": [
    "%%pig\n",
    "r6 = FOREACH r5 GENERATE birthday, mes_f, mes, numMes2;\n",
    "DUMP r6;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " y = FOREACH x GENERATE birthday, mes, mes as (numMes:INT);\n",
      " DUMP y;\n",
      "2020-03-04 03:36:11,675 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 03:36:12,183 [JobControl] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 03:36:12,197 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-03-04 03:36:12,206 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-03-04 03:36:12,232 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-03-04 03:36:12,251 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1583289929631_0032\n",
      "2020-03-04 03:36:12,254 [JobControl] INFO  org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.\n",
      "2020-03-04 03:36:12,276 [JobControl] INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1583289929631_0032\n",
      "2020-03-04 03:36:12,285 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://06626b12eba3:8088/proxy/application_1583289929631_0032/\n",
      "2020-03-04 03:36:27,677 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 03:36:27,679 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-04 03:36:27,734 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 03:36:27,738 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-04 03:36:27,759 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 03:36:27,762 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-04 03:36:27,794 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 03:36:27,799 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-04 03:36:27,823 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 03:36:27,826 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-04 03:36:27,848 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 03:36:27,851 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-04 03:36:27,880 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "(1971-07-08,07,7)\n",
      "(1974-05-23,05,5)\n",
      "(1973-04-22,04,4)\n",
      "(1975-01-29,01,1)\n",
      "(1974-07-03,07,7)\n",
      "(1974-10-18,10,10)\n",
      "(1970-10-05,10,10)\n",
      "(1969-02-24,02,2)\n",
      "(1974-10-17,10,10)\n",
      "(1975-02-28,02,2)\n",
      "(1969-12-07,12,12)\n",
      "(1973-12-24,12,12)\n",
      "(1970-08-27,08,8)\n",
      "(1972-12-12,12,12)\n",
      "(1970-07-01,07,7)\n",
      "(1974-02-11,02,2)\n",
      "(1973-04-01,04,4)\n",
      "(1973-04-29,04,4)\n"
     ]
    }
   ],
   "source": [
    "%%pig\n",
    "z = FOREACH y GENERATE birthday, mes, mes as (numMes:INT);\n",
    "DUMP z;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " DUMP A;\n",
      "2020-03-04 04:34:16,465 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 04:34:16,540 [JobControl] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 04:34:16,558 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-03-04 04:34:16,567 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Cleaning up the staging area /tmp/hadoop-yarn/staging/root/.staging/job_1583289929631_0084\n",
      "2020-03-04 04:34:16,569 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob - PigLatin:DefaultJobName got an error while submitting \n",
      "org.apache.pig.backend.executionengine.ExecException: ERROR 2118: Input path does not exist: hdfs://0.0.0.0:9000/user/root/(3\n",
      "Input path does not exist: hdfs://0.0.0.0:9000/user/root/8\n",
      "Input path does not exist: hdfs://0.0.0.0:9000/user/root/9)\n",
      "\tat org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:294)\n",
      "\tat org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:303)\n",
      "\tat org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:320)\n",
      "\tat org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:198)\n",
      "\tat org.apache.hadoop.mapreduce.Job$11.run(Job.java:1341)\n",
      "\tat org.apache.hadoop.mapreduce.Job$11.run(Job.java:1338)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1844)\n",
      "\tat org.apache.hadoop.mapreduce.Job.submit(Job.java:1338)\n",
      "\tat org.apache.hadoop.mapreduce.lib.jobcontrol.ControlledJob.submit(ControlledJob.java:335)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.pig.backend.hadoop.PigJobControl.submit(PigJobControl.java:128)\n",
      "\tat org.apache.pig.backend.hadoop.PigJobControl.run(PigJobControl.java:205)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\tat org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher$1.run(MapReduceLauncher.java:301)\n",
      "Caused by: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: hdfs://0.0.0.0:9000/user/root/(3\n",
      "Input path does not exist: hdfs://0.0.0.0:9000/user/root/8\n",
      "Input path does not exist: hdfs://0.0.0.0:9000/user/root/9)\n",
      "\tat org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:329)\n",
      "\tat org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:271)\n",
      "\tat org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigTextInputFormat.listStatus(PigTextInputFormat.java:36)\n",
      "\tat org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:393)\n",
      "\tat org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigInputFormat.getSplits(PigInputFormat.java:280)\n",
      "\t... 18 more\n",
      "2020-03-04 04:34:22,052 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 04:34:22,058 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Could not get Job info from RM for job job_1583289929631_0084. Redirecting to job history server.\n",
      "2020-03-04 04:34:22,070 [main] ERROR org.apache.pig.tools.pigstats.PigStats - ERROR 0: java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING\n",
      "2020-03-04 04:34:22,070 [main] ERROR org.apache.pig.tools.pigstats.mapreduce.MRPigStatsUtil - 1 map reduce job(s) failed!\n",
      "2020-03-04 04:34:22,085 [main] ERROR org.apache.pig.tools.grunt.Grunt - ERROR 1066: Unable to open iterator for alias A. Backend error : java.lang.IllegalStateException: Job in state DEFINE instead of RUNNING\n",
      "Details at logfile: /datalake/Talleres jumonsalve/evaluacion-final-juancamilo1203unal/02-pig-50/q29-10/pig_1583295902950.log\n",
      " A = CREATE '3, 8' USING PigStorage(',')\n",
      "    AS (num_f:INT,\n",
      "        mes_f:INT);\n",
      "2020-03-04 04:34:22,203 [main] ERROR org.apache.pig.tools.grunt.Grunt - ERROR 1200: <line 13, column 0>  Syntax error, unexpected symbol at or near 'A'\n",
      "Details at logfile: /datalake/Talleres jumonsalve/evaluacion-final-juancamilo1203unal/02-pig-50/q29-10/pig_1583295902950.log\n"
     ]
    }
   ],
   "source": [
    "%%pig\n",
    "A = CREATE '3, 8' USING PigStorage(',')\n",
    "    AS (num_f:INT,\n",
    "        mes_f:INT);\n",
    "    \n",
    "DUMP A;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pig_quit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################\n",
    "########################################################################################################\n",
    "########################################################################################################\n",
    "########################################################################################################\n",
    "########################################################################################################\n",
    "########################################################################################################\n",
    "## Código en Apache Pig\n",
    "##   Nota. Se usan los dos guiones -- para comentario de una línea y /* … */ para comentarios de varias líneas.\n",
    "########################################################################################################\n",
    "########################################################################################################\n",
    "########################################################################################################\n",
    "########################################################################################################\n",
    "########################################################################################################\n",
    "########################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: `input/*': No such file or directory\n",
      "Deleted output/_SUCCESS\n",
      "Deleted output/part-m-00000\n",
      "rmdir: `input': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "## Limpieza del HDFS y de la máquina local\n",
    "## Se crea el directorio de entrada\n",
    "## Se elimina el directorio de salida en el hdfs si existe\n",
    "!hadoop fs -rm input/*\n",
    "!hadoop fs -rm output/*\n",
    "!hadoop fs -rmdir output input\n",
    "## Se elimina la carpeta si existe\n",
    "!rm -rf output input\n",
    "# !mkdir output input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing script.pig\n"
     ]
    }
   ],
   "source": [
    "%%writefile script.pig\n",
    "\n",
    "\n",
    "--\n",
    "-- Carga el archivo desde el disco duro\n",
    "--\n",
    "u = LOAD 'data.csv' USING PigStorage(',') \n",
    "    AS (id:int, \n",
    "        firstname:CHARARRAY, \n",
    "        surname:CHARARRAY, \n",
    "        birthday:CHARARRAY, \n",
    "        color:CHARARRAY, \n",
    "        quantity:INT);\n",
    "    \n",
    "x = FOREACH u GENERATE id, birthday, REGEX_EXTRACT(birthday, '(.*)-(.*)-(.*)',2) AS mes;\n",
    "y = FOREACH x GENERATE id, birthday, mes, mes as (numMes:INT);\n",
    "\n",
    "%%writefile meses.txt\n",
    "1\tjan\n",
    "2\tfeb\n",
    "3\tmar\n",
    "4\tapr\n",
    "5\tmay\n",
    "6\tjun\n",
    "7\tjul\n",
    "8\taug\n",
    "9\tsep\n",
    "10\toct\n",
    "11\tnov\n",
    "12\tdic\n",
    "\n",
    "m = LOAD 'meses.txt' USING PigStorage()\n",
    "    AS (num_f:INT,\n",
    "        mes_f:CHARARRAY);\n",
    "\n",
    "\n",
    "TempR4 = JOIN y BY numMes, m BY num_f;\n",
    "r4 = FOREACH TempR4 GENERATE id, birthday, mes_f, mes, mes as (numMes2:INT);\n",
    "r5 = ORDER r4 BY id;\n",
    "r6 = FOREACH r5 GENERATE birthday, mes_f, mes, numMes2;\n",
    "\n",
    "-- escribe el archivo de salida\n",
    "STORE r6 INTO 'output' USING PigStorage(',');\n",
    "\n",
    "-- copia los archivos del HDFS al sistema local\n",
    "fs -get output/ ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-04 03:28:48,151 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2020-03-04 03:28:49,538 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.textoutputformat.separator is deprecated. Instead, use mapreduce.output.textoutputformat.separator\n",
      "2020-03-04 03:28:49,846 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 03:28:50,045 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2020-03-04 03:28:50,049 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.compress is deprecated. Instead, use mapreduce.output.fileoutputformat.compress\n",
      "2020-03-04 03:28:50,063 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.submit.replication is deprecated. Instead, use mapreduce.client.submit.file.replication\n",
      "2020-03-04 03:28:50,819 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker.http.address is deprecated. Instead, use mapreduce.jobtracker.http.address\n",
      "2020-03-04 03:28:50,827 [JobControl] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 03:28:50,845 [JobControl] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
      "2020-03-04 03:28:50,944 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-03-04 03:28:50,978 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-03-04 03:28:51,054 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-03-04 03:28:51,195 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1583289929631_0026\n",
      "2020-03-04 03:28:51,373 [JobControl] INFO  org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.\n",
      "2020-03-04 03:28:51,457 [JobControl] INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1583289929631_0026\n",
      "2020-03-04 03:28:51,503 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://06626b12eba3:8088/proxy/application_1583289929631_0026/\n",
      "2020-03-04 03:29:06,622 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 03:29:06,627 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-04 03:29:06,784 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 03:29:06,789 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-04 03:29:06,823 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2020-03-04 03:29:06,826 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 03:29:06,831 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-04 03:29:06,898 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 03:29:06,902 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-04 03:29:06,938 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 03:29:06,942 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-03-04 03:29:06,979 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-03-04 03:29:06,984 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n"
     ]
    }
   ],
   "source": [
    "## Ejecución del script en modo batch\n",
    "!pig -execute 'run script.pig'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1971-07-08,1971,71\n",
      "1974-05-23,1974,74\n",
      "1973-04-22,1973,73\n",
      "1975-01-29,1975,75\n",
      "1974-07-03,1974,74\n",
      "1974-10-18,1974,74\n",
      "1970-10-05,1970,70\n",
      "1969-02-24,1969,69\n",
      "1974-10-17,1974,74\n",
      "1975-02-28,1975,75\n",
      "1969-12-07,1969,69\n",
      "1973-12-24,1973,73\n",
      "1970-08-27,1970,70\n",
      "1972-12-12,1972,72\n",
      "1970-07-01,1970,70\n",
      "1974-02-11,1974,74\n",
      "1973-04-01,1973,73\n",
      "1973-04-29,1973,73\n"
     ]
    }
   ],
   "source": [
    "## Visualización de los resultados en el HDFS\n",
    "!hadoop fs -cat output/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1971-07-08,1971,71\n",
      "1974-05-23,1974,74\n",
      "1973-04-22,1973,73\n",
      "1975-01-29,1975,75\n",
      "1974-07-03,1974,74\n",
      "1974-10-18,1974,74\n",
      "1970-10-05,1970,70\n",
      "1969-02-24,1969,69\n",
      "1974-10-17,1974,74\n",
      "1975-02-28,1975,75\n",
      "1969-12-07,1969,69\n",
      "1973-12-24,1973,73\n",
      "1970-08-27,1970,70\n",
      "1972-12-12,1972,72\n",
      "1970-07-01,1970,70\n",
      "1974-02-11,1974,74\n",
      "1973-04-01,1973,73\n",
      "1973-04-29,1973,73\n"
     ]
    }
   ],
   "source": [
    "## Visualilzación de resultados en el sistema local\n",
    "!cat output/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: `input/*': No such file or directory\n",
      "Deleted output/_SUCCESS\n",
      "Deleted output/part-m-00000\n",
      "rmdir: `input': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "## Limpieza del HDFS y de la máquina local\n",
    "## Se crea el directorio de entrada\n",
    "## Se elimina el directorio de salida en el hdfs si existe\n",
    "!hadoop fs -rm input/*\n",
    "!hadoop fs -rm output/*\n",
    "!hadoop fs -rmdir output input\n",
    "## Se elimina la carpeta si existe\n",
    "!rm -rf output input\n",
    "# !mkdir output input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
