{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "put: `data.tsv': File exists\n",
      "Found 2 items\n",
      "-rw-r--r--   1 root supergroup       1780 2020-02-29 02:01 data.tsv\n",
      "drwxr-xr-x   - root supergroup          0 2020-02-29 02:42 output\n"
     ]
    }
   ],
   "source": [
    "########################################################################################################\n",
    "## Ejecución de Pig en Jupyter\n",
    "##    A continuación se describe como ejecutar comandos de Pig en Jupyter usando la extensión de Jupyter bigdata.\n",
    "%load_ext bigdata\n",
    "%pig_start\n",
    "%timeout 300\n",
    "## WordCount en Apache Pig\n",
    "##   Se cargan los archivos en Apache Pig.\n",
    "!hadoop fs -put *.tsv .\n",
    "!hadoop fs -ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eg2:MAP[]);AD 'data.tsv' AS (clave:CHARARRAY, reg1:BAG{t:(p:CHARARRAY)}, r \n",
      " DUMP lines;\n",
      "2020-02-29 02:45:22,901 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:45:23,082 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2020-02-29 02:45:23,086 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.compress is deprecated. Instead, use mapreduce.output.fileoutputformat.compress\n",
      "2020-02-29 02:45:23,097 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.submit.replication is deprecated. Instead, use mapreduce.client.submit.file.replication\n",
      "2020-02-29 02:45:23,836 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker.http.address is deprecated. Instead, use mapreduce.jobtracker.http.address\n",
      "2020-02-29 02:45:23,843 [JobControl] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:45:23,872 [JobControl] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
      "2020-02-29 02:45:23,965 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-02-29 02:45:24,003 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-02-29 02:45:24,084 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-02-29 02:45:24,207 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1582941575110_0030\n",
      "2020-02-29 02:45:24,327 [JobControl] INFO  org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.\n",
      "2020-02-29 02:45:24,457 [JobControl] INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1582941575110_0030\n",
      "2020-02-29 02:45:24,490 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://7b1cffac5c23:8088/proxy/application_1582941575110_0030/\n",
      "2020-02-29 02:45:39,620 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:45:39,625 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:45:39,806 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:45:39,818 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:45:39,851 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2020-02-29 02:45:39,852 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:45:39,858 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:45:39,926 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:45:39,931 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:45:39,969 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:45:39,973 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:45:39,998 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:45:40,003 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:45:40,053 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "(E,{(b),(g),(f)},[hhh#2,bbb#0,jjj#3,ddd#9,ggg#8])\n",
      "(A,{(a),(f),(c)},[aaa#3,hhh#9,ccc#2,ddd#0])\n",
      "(B,{(f),(e),(a),(c)},[ccc#6,jjj#1,ddd#2,ggg#5])\n",
      "(A,{(a),(b)},[iii#5,hhh#9,bbb#1,eee#7])\n",
      "(C,{(f),(g),(d),(a)},[iii#6,jjj#3,eee#4,ddd#5])\n",
      "(A,{(c),(d)},[aaa#7,hhh#0,ccc#4,bbb#2,fff#1])\n",
      "(A,{(g),(d),(a)},[aaa#5,iii#0,ccc#1,jjj#7,ddd#2,fff#8])\n",
      "(B,{(b),(a)},[ddd#2,hhh#1,fff#3])\n",
      "(E,{(d),(e),(a),(f)},[iii#9,ccc#5,bbb#0,eee#4,ggg#6,fff#7])\n",
      "(B,{(d),(b),(g),(f)},[iii#4,bbb#7,jjj#9,eee#3,ggg#2,fff#5])\n",
      "(C,{(d),(c),(f),(b)},[iii#0,hhh#6,jjj#1,eee#4,fff#2])\n",
      "(C,{(d),(e),(a),(c)},[iii#6,ggg#9,bbb#7])\n",
      "(D,{(g),(e),(f),(b)},[aaa#3,ccc#6,bbb#9,eee#2,fff#4])\n",
      "(E,{(c),(f)},[aaa#8,ddd#5,jjj#1])\n",
      "(B,{(d),(b)},[aaa#2,ccc#0,jjj#6,ddd#3,fff#7])\n",
      "(D,{(f),(e)},[ccc#0,bbb#9,eee#6,ddd#3])\n",
      "(E,{(e),(b),(f)},[iii#3,hhh#5,bbb#6,ddd#2,ggg#9,fff#4])\n",
      "(D,{(g),(a)},[hhh#4,ccc#9,jjj#5])\n",
      "(E,{(e),(c),(f),(a)},[iii#6,ccc#1,fff#9])\n",
      "(E,{(e),(a)},[aaa#3,bbb#9,fff#1])\n",
      "(E,{(e),(f)},[aaa#4,iii#2,ddd#9])\n",
      "(E,{(c),(b),(g)},[iii#7,ccc#5,fff#8])\n",
      "(D,{(c),(f),(a)},[eee#3,ddd#7,jjj#2])\n",
      "(A,{(f),(a),(d)},[ccc#7,bbb#3,jjj#1,ddd#9,ggg#0])\n",
      "(E,{(c),(d)},[aaa#1,iii#7,hhh#9,ccc#0,jjj#6,ggg#8])\n",
      "(E,{(e),(d),(c)},[iii#4,ccc#1,bbb#7,eee#6,ddd#0,fff#3])\n",
      "(A,{(a),(e),(f)},[ddd#5,ccc#4,fff#0])\n",
      "(E,{(c),(a),(g)},[hhh#3,ccc#0,jjj#7,ddd#9,ggg#6])\n",
      "(A,{(f),(e)},[iii#7,hhh#6,ccc#3,jjj#0,eee#5])\n",
      "(C,{(f),(c),(a),(g)},[aaa#2,ccc#7,eee#1,ddd#6,ggg#0,fff#4])\n",
      "(A,{(b),(f)},[aaa#9,ccc#6,bbb#3,eee#5,ddd#0])\n",
      "(D,{(b),(f)},[aaa#6,iii#4,hhh#1,bbb#7,ddd#5,fff#9])\n",
      "(E,{(a),(c)},[ccc#1,eee#5,ggg#2,fff#3])\n",
      "(B,{(b),(f),(c)},[iii#7,hhh#5,ccc#1,jjj#8,ddd#0,ggg#3])\n",
      "(B,{(f),(a),(e)},[hhh#6,ccc#3,bbb#8,jjj#0,ddd#7])\n",
      "(D,{(a),(f)},[aaa#0,ddd#3,fff#5])\n",
      "(B,{(c),(a)},[iii#7,ccc#0,bbb#4,jjj#2,ddd#5])\n",
      "(C,{(c),(a),(e),(f)},[eee#0,hhh#6,fff#2])\n",
      "(E,{(e),(d)},[eee#0,iii#2,fff#9])\n",
      "(E,{(f),(a),(d)},[hhh#8,ggg#3,jjj#5])\n"
     ]
    }
   ],
   "source": [
    "%%pig\n",
    "lines = LOAD 'data.tsv' AS (clave:CHARARRAY, reg1:BAG{t:(p:CHARARRAY)}, reg2:MAP[]);\n",
    "DUMP lines;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --\n",
      " -- Los campos del archivo puden ser indicados por nombre\n",
      " -- o por posici??n iniciando en 0\n",
      " --\n",
      " x = FOREACH lines GENERATE clave, SIZE(reg1), SIZE(reg2);\n",
      " y = ORDER x BY $0, $1, $2;\n",
      " DUMP y;\n",
      "2020-02-29 02:50:48,384 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:50:48,892 [JobControl] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:50:48,916 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-02-29 02:50:48,925 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-02-29 02:50:49,355 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-02-29 02:50:49,371 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1582941575110_0033\n",
      "2020-02-29 02:50:49,373 [JobControl] INFO  org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.\n",
      "2020-02-29 02:50:49,402 [JobControl] INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1582941575110_0033\n",
      "2020-02-29 02:50:49,405 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://7b1cffac5c23:8088/proxy/application_1582941575110_0033/\n",
      "2020-02-29 02:51:04,545 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:51:04,549 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:51:04,608 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:51:04,611 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:51:04,630 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:51:04,633 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:51:04,760 [JobControl] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:51:04,774 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-02-29 02:51:04,784 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-02-29 02:51:04,813 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-02-29 02:51:04,853 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1582941575110_0034\n",
      "2020-02-29 02:51:04,855 [JobControl] INFO  org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.\n",
      "2020-02-29 02:51:05,081 [JobControl] INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1582941575110_0034\n",
      "2020-02-29 02:51:05,084 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://7b1cffac5c23:8088/proxy/application_1582941575110_0034/\n",
      "2020-02-29 02:51:25,387 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:51:25,392 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:51:25,459 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:51:25,463 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:51:25,491 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:51:25,493 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:51:25,621 [JobControl] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:51:25,635 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-02-29 02:51:25,647 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-02-29 02:51:26,480 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-02-29 02:51:26,497 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1582941575110_0035\n",
      "2020-02-29 02:51:26,500 [JobControl] INFO  org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.\n",
      "2020-02-29 02:51:26,529 [JobControl] INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1582941575110_0035\n",
      "2020-02-29 02:51:26,533 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://7b1cffac5c23:8088/proxy/application_1582941575110_0035/\n",
      "2020-02-29 02:51:46,661 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:51:46,669 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:51:46,734 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:51:46,739 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:51:46,764 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:51:46,767 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:51:46,809 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:51:46,811 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:51:46,834 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:51:46,837 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:51:46,859 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:51:46,861 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:51:46,888 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:51:46,891 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:51:46,913 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:51:46,915 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:51:46,936 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:51:46,939 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:51:46,963 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:51:46,966 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:51:46,989 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:51:46,991 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:51:47,013 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:51:47,015 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:51:47,053 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "(A,2,4)\n",
      "(A,2,5)\n",
      "(A,2,5)\n",
      "(A,2,5)\n",
      "(A,3,3)\n",
      "(A,3,4)\n",
      "(A,3,5)\n",
      "(A,3,6)\n",
      "(B,2,3)\n",
      "(B,2,5)\n",
      "(B,2,5)\n",
      "(B,3,5)\n",
      "(B,3,6)\n",
      "(B,4,4)\n",
      "(B,4,6)\n",
      "(C,4,3)\n",
      "(C,4,3)\n",
      "(C,4,4)\n",
      "(C,4,5)\n",
      "(C,4,6)\n",
      "(D,2,3)\n",
      "(D,2,3)\n",
      "(D,2,4)\n",
      "(D,2,6)\n",
      "(D,3,3)\n",
      "(D,4,5)\n",
      "(E,2,3)\n",
      "(E,2,3)\n",
      "(E,2,3)\n",
      "(E,2,3)\n",
      "(E,2,4)\n",
      "(E,2,6)\n",
      "(E,3,3)\n",
      "(E,3,3)\n",
      "(E,3,5)\n",
      "(E,3,5)\n",
      "(E,3,6)\n",
      "(E,3,6)\n",
      "(E,4,3)\n",
      "(E,4,6)\n"
     ]
    }
   ],
   "source": [
    "%%pig\n",
    "--\n",
    "-- Los campos del archivo puden ser indicados por nombre\n",
    "-- o por posición iniciando en 0\n",
    "--\n",
    "x = FOREACH lines GENERATE clave, SIZE(reg1), SIZE(reg2);\n",
    "y = ORDER x BY $0, $1, $2;\n",
    "DUMP y;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pig_quit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################\n",
    "########################################################################################################\n",
    "########################################################################################################\n",
    "########################################################################################################\n",
    "########################################################################################################\n",
    "########################################################################################################\n",
    "## Código en Apache Pig\n",
    "##   Nota. Se usan los dos guiones -- para comentario de una línea y /* … */ para comentarios de varias líneas.\n",
    "########################################################################################################\n",
    "########################################################################################################\n",
    "########################################################################################################\n",
    "########################################################################################################\n",
    "########################################################################################################\n",
    "########################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: `input/*': No such file or directory\n",
      "Deleted output/_SUCCESS\n",
      "Deleted output/part-r-00000\n",
      "rmdir: `input': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "## Limpieza del HDFS y de la máquina local\n",
    "## Se crea el directorio de entrada\n",
    "## Se elimina el directorio de salida en el hdfs si existe\n",
    "!hadoop fs -rm input/*\n",
    "!hadoop fs -rm output/*\n",
    "!hadoop fs -rmdir output input\n",
    "## Se elimina la carpeta si existe\n",
    "!rm -rf output input\n",
    "# !mkdir output input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting script.pig\n"
     ]
    }
   ],
   "source": [
    "%%writefile script.pig\n",
    "\n",
    "-- carga de datos\n",
    "lines = LOAD 'data.tsv' AS (clave:CHARARRAY, reg1:BAG{t:(p:CHARARRAY)}, reg2:MAP[]);\n",
    "\n",
    "-- Los campos del archivo puden ser indicados por nombre\n",
    "-- o por posición iniciando en 0\n",
    "--\n",
    "x = FOREACH lines GENERATE clave, SIZE(reg1), SIZE(reg2);\n",
    "y = ORDER x BY $0, $1, $2;\n",
    "\n",
    "-- escribe el archivo de salida\n",
    "STORE y INTO 'output' USING PigStorage(',');\n",
    "\n",
    "-- copia los archivos del HDFS al sistema local\n",
    "fs -get output/ ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-29 02:54:55,940 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2020-02-29 02:54:57,286 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.textoutputformat.separator is deprecated. Instead, use mapreduce.output.textoutputformat.separator\n",
      "2020-02-29 02:54:57,625 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:54:57,797 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2020-02-29 02:54:57,801 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.compress is deprecated. Instead, use mapreduce.output.fileoutputformat.compress\n",
      "2020-02-29 02:54:57,814 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.submit.replication is deprecated. Instead, use mapreduce.client.submit.file.replication\n",
      "2020-02-29 02:54:58,105 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker.http.address is deprecated. Instead, use mapreduce.jobtracker.http.address\n",
      "2020-02-29 02:54:58,113 [JobControl] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:54:58,129 [JobControl] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
      "2020-02-29 02:54:58,210 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-02-29 02:54:58,240 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-02-29 02:54:58,307 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-02-29 02:54:58,910 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1582941575110_0040\n",
      "2020-02-29 02:54:59,092 [JobControl] INFO  org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.\n",
      "2020-02-29 02:54:59,178 [JobControl] INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1582941575110_0040\n",
      "2020-02-29 02:54:59,217 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://7b1cffac5c23:8088/proxy/application_1582941575110_0040/\n",
      "2020-02-29 02:55:14,349 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:55:14,354 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:55:14,539 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:55:14,543 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:55:14,569 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2020-02-29 02:55:14,572 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:55:14,578 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:55:14,863 [JobControl] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:55:14,884 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-02-29 02:55:14,905 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-02-29 02:55:14,934 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-02-29 02:55:14,963 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1582941575110_0041\n",
      "2020-02-29 02:55:14,968 [JobControl] INFO  org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.\n",
      "2020-02-29 02:55:14,997 [JobControl] INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1582941575110_0041\n",
      "2020-02-29 02:55:15,004 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://7b1cffac5c23:8088/proxy/application_1582941575110_0041/\n",
      "2020-02-29 02:55:35,066 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:55:35,073 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:55:35,645 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:55:35,650 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:55:35,684 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:55:35,687 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:55:35,875 [JobControl] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:55:35,901 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-02-29 02:55:35,915 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-02-29 02:55:35,945 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-02-29 02:55:35,982 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1582941575110_0042\n",
      "2020-02-29 02:55:35,985 [JobControl] INFO  org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.\n",
      "2020-02-29 02:55:36,020 [JobControl] INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1582941575110_0042\n",
      "2020-02-29 02:55:36,026 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://7b1cffac5c23:8088/proxy/application_1582941575110_0042/\n",
      "2020-02-29 02:56:01,509 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:56:01,515 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:56:01,577 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:56:01,581 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:56:01,613 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:56:01,616 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:56:01,667 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:56:01,671 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:56:01,707 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:56:01,711 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:56:01,742 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:56:01,746 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:56:01,788 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:56:01,792 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:56:01,832 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:56:01,836 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:56:01,891 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:56:01,895 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:56:01,937 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:56:01,941 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:56:01,979 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:56:01,983 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:56:02,022 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:56:02,025 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n"
     ]
    }
   ],
   "source": [
    "## Ejecución del script en modo batch\n",
    "!pig -execute 'run script.pig'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,2,4\n",
      "A,2,5\n",
      "A,2,5\n",
      "A,2,5\n",
      "A,3,3\n",
      "A,3,4\n",
      "A,3,5\n",
      "A,3,6\n",
      "B,2,3\n",
      "B,2,5\n",
      "B,2,5\n",
      "B,3,5\n",
      "B,3,6\n",
      "B,4,4\n",
      "B,4,6\n",
      "C,4,3\n",
      "C,4,3\n",
      "C,4,4\n",
      "C,4,5\n",
      "C,4,6\n",
      "D,2,3\n",
      "D,2,3\n",
      "D,2,4\n",
      "D,2,6\n",
      "D,3,3\n",
      "D,4,5\n",
      "E,2,3\n",
      "E,2,3\n",
      "E,2,3\n",
      "E,2,3\n",
      "E,2,4\n",
      "E,2,6\n",
      "E,3,3\n",
      "E,3,3\n",
      "E,3,5\n",
      "E,3,5\n",
      "E,3,6\n",
      "E,3,6\n",
      "E,4,3\n",
      "E,4,6\n"
     ]
    }
   ],
   "source": [
    "## Visualización de los resultados en el HDFS\n",
    "!hadoop fs -cat output/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A,2,4\n",
      "A,2,5\n",
      "A,2,5\n",
      "A,2,5\n",
      "A,3,3\n",
      "A,3,4\n",
      "A,3,5\n",
      "A,3,6\n",
      "B,2,3\n",
      "B,2,5\n",
      "B,2,5\n",
      "B,3,5\n",
      "B,3,6\n",
      "B,4,4\n",
      "B,4,6\n",
      "C,4,3\n",
      "C,4,3\n",
      "C,4,4\n",
      "C,4,5\n",
      "C,4,6\n",
      "D,2,3\n",
      "D,2,3\n",
      "D,2,4\n",
      "D,2,6\n",
      "D,3,3\n",
      "D,4,5\n",
      "E,2,3\n",
      "E,2,3\n",
      "E,2,3\n",
      "E,2,3\n",
      "E,2,4\n",
      "E,2,6\n",
      "E,3,3\n",
      "E,3,3\n",
      "E,3,5\n",
      "E,3,5\n",
      "E,3,6\n",
      "E,3,6\n",
      "E,4,3\n",
      "E,4,6\n"
     ]
    }
   ],
   "source": [
    "## Visualilzación de resultados en el sistema local\n",
    "!cat output/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
