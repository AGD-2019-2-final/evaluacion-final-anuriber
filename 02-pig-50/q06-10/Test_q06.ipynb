{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "put: `data.tsv': File exists\n",
      "Found 2 items\n",
      "-rw-r--r--   1 root supergroup       1780 2020-02-29 02:01 data.tsv\n",
      "drwxr-xr-x   - root supergroup          0 2020-02-29 02:20 output\n"
     ]
    }
   ],
   "source": [
    "########################################################################################################\n",
    "## Ejecución de Pig en Jupyter\n",
    "##    A continuación se describe como ejecutar comandos de Pig en Jupyter usando la extensión de Jupyter bigdata.\n",
    "%load_ext bigdata\n",
    "%pig_start\n",
    "%timeout 300\n",
    "## WordCount en Apache Pig\n",
    "##   Se cargan los archivos en Apache Pig.\n",
    "!hadoop fs -put *.tsv .\n",
    "!hadoop fs -ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eg2:MAP[]);AD 'data.tsv' AS (clave:CHARARRAY, reg1:BAG{t:(p:CHARARRAY)}, r \n",
      " DUMP lines;\n",
      "2020-02-29 02:22:36,185 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:22:36,352 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2020-02-29 02:22:36,356 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.compress is deprecated. Instead, use mapreduce.output.fileoutputformat.compress\n",
      "2020-02-29 02:22:36,367 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.submit.replication is deprecated. Instead, use mapreduce.client.submit.file.replication\n",
      "2020-02-29 02:22:37,113 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker.http.address is deprecated. Instead, use mapreduce.jobtracker.http.address\n",
      "2020-02-29 02:22:37,122 [JobControl] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:22:37,142 [JobControl] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
      "2020-02-29 02:22:37,221 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-02-29 02:22:37,246 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-02-29 02:22:37,714 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-02-29 02:22:37,839 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1582941575110_0012\n",
      "2020-02-29 02:22:37,961 [JobControl] INFO  org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.\n",
      "2020-02-29 02:22:38,088 [JobControl] INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1582941575110_0012\n",
      "2020-02-29 02:22:38,121 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://7b1cffac5c23:8088/proxy/application_1582941575110_0012/\n",
      "2020-02-29 02:22:53,227 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:22:53,232 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:22:53,378 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:22:53,382 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:22:53,408 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2020-02-29 02:22:53,411 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:22:53,415 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:22:53,475 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:22:53,481 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:22:53,512 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:22:53,516 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:22:53,541 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:22:53,545 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:22:53,600 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "(E,{(b),(g),(f)},[hhh#2,bbb#0,jjj#3,ddd#9,ggg#8])\n",
      "(A,{(a),(f),(c)},[aaa#3,hhh#9,ccc#2,ddd#0])\n",
      "(B,{(f),(e),(a),(c)},[ccc#6,jjj#1,ddd#2,ggg#5])\n",
      "(A,{(a),(b)},[iii#5,hhh#9,bbb#1,eee#7])\n",
      "(C,{(f),(g),(d),(a)},[iii#6,jjj#3,eee#4,ddd#5])\n",
      "(A,{(c),(d)},[aaa#7,hhh#0,ccc#4,bbb#2,fff#1])\n",
      "(A,{(g),(d),(a)},[aaa#5,iii#0,ccc#1,jjj#7,ddd#2,fff#8])\n",
      "(B,{(b),(a)},[ddd#2,hhh#1,fff#3])\n",
      "(E,{(d),(e),(a),(f)},[iii#9,ccc#5,bbb#0,eee#4,ggg#6,fff#7])\n",
      "(B,{(d),(b),(g),(f)},[iii#4,bbb#7,jjj#9,eee#3,ggg#2,fff#5])\n",
      "(C,{(d),(c),(f),(b)},[iii#0,hhh#6,jjj#1,eee#4,fff#2])\n",
      "(C,{(d),(e),(a),(c)},[iii#6,ggg#9,bbb#7])\n",
      "(D,{(g),(e),(f),(b)},[aaa#3,ccc#6,bbb#9,eee#2,fff#4])\n",
      "(E,{(c),(f)},[aaa#8,ddd#5,jjj#1])\n",
      "(B,{(d),(b)},[aaa#2,ccc#0,jjj#6,ddd#3,fff#7])\n",
      "(D,{(f),(e)},[ccc#0,bbb#9,eee#6,ddd#3])\n",
      "(E,{(e),(b),(f)},[iii#3,hhh#5,bbb#6,ddd#2,ggg#9,fff#4])\n",
      "(D,{(g),(a)},[hhh#4,ccc#9,jjj#5])\n",
      "(E,{(e),(c),(f),(a)},[iii#6,ccc#1,fff#9])\n",
      "(E,{(e),(a)},[aaa#3,bbb#9,fff#1])\n",
      "(E,{(e),(f)},[aaa#4,iii#2,ddd#9])\n",
      "(E,{(c),(b),(g)},[iii#7,ccc#5,fff#8])\n",
      "(D,{(c),(f),(a)},[eee#3,ddd#7,jjj#2])\n",
      "(A,{(f),(a),(d)},[ccc#7,bbb#3,jjj#1,ddd#9,ggg#0])\n",
      "(E,{(c),(d)},[aaa#1,iii#7,hhh#9,ccc#0,jjj#6,ggg#8])\n",
      "(E,{(e),(d),(c)},[iii#4,ccc#1,bbb#7,eee#6,ddd#0,fff#3])\n",
      "(A,{(a),(e),(f)},[ddd#5,ccc#4,fff#0])\n",
      "(E,{(c),(a),(g)},[hhh#3,ccc#0,jjj#7,ddd#9,ggg#6])\n",
      "(A,{(f),(e)},[iii#7,hhh#6,ccc#3,jjj#0,eee#5])\n",
      "(C,{(f),(c),(a),(g)},[aaa#2,ccc#7,eee#1,ddd#6,ggg#0,fff#4])\n",
      "(A,{(b),(f)},[aaa#9,ccc#6,bbb#3,eee#5,ddd#0])\n",
      "(D,{(b),(f)},[aaa#6,iii#4,hhh#1,bbb#7,ddd#5,fff#9])\n",
      "(E,{(a),(c)},[ccc#1,eee#5,ggg#2,fff#3])\n",
      "(B,{(b),(f),(c)},[iii#7,hhh#5,ccc#1,jjj#8,ddd#0,ggg#3])\n",
      "(B,{(f),(a),(e)},[hhh#6,ccc#3,bbb#8,jjj#0,ddd#7])\n",
      "(D,{(a),(f)},[aaa#0,ddd#3,fff#5])\n",
      "(B,{(c),(a)},[iii#7,ccc#0,bbb#4,jjj#2,ddd#5])\n",
      "(C,{(c),(a),(e),(f)},[eee#0,hhh#6,fff#2])\n",
      "(E,{(e),(d)},[eee#0,iii#2,fff#9])\n",
      "(E,{(f),(a),(d)},[hhh#8,ggg#3,jjj#5])\n"
     ]
    }
   ],
   "source": [
    "%%pig\n",
    "lines = LOAD 'data.tsv' AS (clave:CHARARRAY, reg1:BAG{t:(p:CHARARRAY)}, reg2:MAP[]);\n",
    "DUMP lines;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -- genera una tabla llamada words con una palabra por registro\n",
      "eg2:MAP[]);AD 'data.tsv' AS (clave:CHARARRAY, reg1:BAG{t:(p:CHARARRAY)}, r \n",
      " words = FOREACH lines GENERATE FLATTEN(reg2) AS word;\n",
      " DUMP words;\n",
      "2020-02-29 02:35:28,133 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:35:29,470 [JobControl] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:35:29,481 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-02-29 02:35:29,491 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-02-29 02:35:29,514 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-02-29 02:35:29,528 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1582941575110_0024\n",
      "2020-02-29 02:35:29,530 [JobControl] INFO  org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.\n",
      "2020-02-29 02:35:29,555 [JobControl] INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1582941575110_0024\n",
      "2020-02-29 02:35:29,561 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://7b1cffac5c23:8088/proxy/application_1582941575110_0024/\n",
      "2020-02-29 02:35:44,704 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:35:44,707 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:35:44,773 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:35:44,778 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:35:44,804 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:35:44,806 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:35:44,825 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:35:44,827 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:35:44,846 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:35:44,848 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:35:44,866 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:35:44,868 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:35:44,891 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "(bbb,0)\n",
      "(ddd,9)\n",
      "(ggg,8)\n",
      "(hhh,2)\n",
      "(jjj,3)\n",
      "(aaa,3)\n",
      "(ccc,2)\n",
      "(ddd,0)\n",
      "(hhh,9)\n",
      "(ccc,6)\n",
      "(ddd,2)\n",
      "(ggg,5)\n",
      "(jjj,1)\n",
      "(bbb,1)\n",
      "(eee,7)\n",
      "(iii,5)\n",
      "(hhh,9)\n",
      "(eee,4)\n",
      "(ddd,5)\n",
      "(iii,6)\n",
      "(jjj,3)\n",
      "(aaa,7)\n",
      "(ccc,4)\n",
      "(bbb,2)\n",
      "(fff,1)\n",
      "(hhh,0)\n",
      "(aaa,5)\n",
      "(ccc,1)\n",
      "(ddd,2)\n",
      "(fff,8)\n",
      "(iii,0)\n",
      "(jjj,7)\n",
      "(ddd,2)\n",
      "(fff,3)\n",
      "(hhh,1)\n",
      "(ccc,5)\n",
      "(bbb,0)\n",
      "(eee,4)\n",
      "(ggg,6)\n",
      "(fff,7)\n",
      "(iii,9)\n",
      "(bbb,7)\n",
      "(eee,3)\n",
      "(ggg,2)\n",
      "(fff,5)\n",
      "(iii,4)\n",
      "(jjj,9)\n",
      "(eee,4)\n",
      "(fff,2)\n",
      "(iii,0)\n",
      "(hhh,6)\n",
      "(jjj,1)\n",
      "(bbb,7)\n",
      "(ggg,9)\n",
      "(iii,6)\n",
      "(aaa,3)\n",
      "(ccc,6)\n",
      "(bbb,9)\n",
      "(eee,2)\n",
      "(fff,4)\n",
      "(aaa,8)\n",
      "(ddd,5)\n",
      "(jjj,1)\n",
      "(aaa,2)\n",
      "(ccc,0)\n",
      "(ddd,3)\n",
      "(fff,7)\n",
      "(jjj,6)\n",
      "(ccc,0)\n",
      "(bbb,9)\n",
      "(eee,6)\n",
      "(ddd,3)\n",
      "(bbb,6)\n",
      "(ddd,2)\n",
      "(ggg,9)\n",
      "(fff,4)\n",
      "(iii,3)\n",
      "(hhh,5)\n",
      "(ccc,9)\n",
      "(hhh,4)\n",
      "(jjj,5)\n",
      "(ccc,1)\n",
      "(fff,9)\n",
      "(iii,6)\n",
      "(aaa,3)\n",
      "(bbb,9)\n",
      "(fff,1)\n",
      "(aaa,4)\n",
      "(ddd,9)\n",
      "(iii,2)\n",
      "(ccc,5)\n",
      "(fff,8)\n",
      "(iii,7)\n",
      "(eee,3)\n",
      "(ddd,7)\n",
      "(jjj,2)\n",
      "(ccc,7)\n",
      "(bbb,3)\n",
      "(ddd,9)\n",
      "(ggg,0)\n",
      "(jjj,1)\n",
      "(aaa,1)\n",
      "(ccc,0)\n",
      "(ggg,8)\n",
      "(iii,7)\n",
      "(hhh,9)\n",
      "(jjj,6)\n",
      "(ccc,1)\n",
      "(bbb,7)\n",
      "(eee,6)\n",
      "(ddd,0)\n",
      "(fff,3)\n",
      "(iii,4)\n",
      "(ccc,4)\n",
      "(ddd,5)\n",
      "(fff,0)\n",
      "(ccc,0)\n",
      "(ddd,9)\n",
      "(ggg,6)\n",
      "(hhh,3)\n",
      "(jjj,7)\n",
      "(ccc,3)\n",
      "(eee,5)\n",
      "(iii,7)\n",
      "(hhh,6)\n",
      "(jjj,0)\n",
      "(aaa,2)\n",
      "(ccc,7)\n",
      "(eee,1)\n",
      "(ddd,6)\n",
      "(ggg,0)\n",
      "(fff,4)\n",
      "(aaa,9)\n",
      "(ccc,6)\n",
      "(bbb,3)\n",
      "(eee,5)\n",
      "(ddd,0)\n",
      "(aaa,6)\n",
      "(bbb,7)\n",
      "(ddd,5)\n",
      "(fff,9)\n",
      "(iii,4)\n",
      "(hhh,1)\n",
      "(ccc,1)\n",
      "(eee,5)\n",
      "(ggg,2)\n",
      "(fff,3)\n",
      "(ccc,1)\n",
      "(ddd,0)\n",
      "(ggg,3)\n",
      "(iii,7)\n",
      "(hhh,5)\n",
      "(jjj,8)\n",
      "(ccc,3)\n",
      "(bbb,8)\n",
      "(ddd,7)\n",
      "(hhh,6)\n",
      "(jjj,0)\n",
      "(aaa,0)\n",
      "(ddd,3)\n",
      "(fff,5)\n",
      "(ccc,0)\n",
      "(bbb,4)\n",
      "(ddd,5)\n",
      "(iii,7)\n",
      "(jjj,2)\n",
      "(eee,0)\n",
      "(fff,2)\n",
      "(hhh,6)\n",
      "(eee,0)\n",
      "(fff,9)\n",
      "(iii,2)\n",
      "(ggg,3)\n",
      "(hhh,8)\n",
      "(jjj,5)\n"
     ]
    }
   ],
   "source": [
    "%%pig\n",
    "-- genera una tabla llamada words con una palabra por registro\n",
    "words = FOREACH lines GENERATE FLATTEN(reg2) AS word;\n",
    "DUMP words;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -- agrupa los registros que tienen la misma palabra\n",
      " grouped = GROUP words BY word;\n",
      " DUMP grouped;\n",
      "2020-02-29 02:36:21,614 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:36:22,119 [JobControl] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:36:22,137 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-02-29 02:36:22,144 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-02-29 02:36:22,169 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-02-29 02:36:22,187 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1582941575110_0025\n",
      "2020-02-29 02:36:22,190 [JobControl] INFO  org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.\n",
      "2020-02-29 02:36:22,212 [JobControl] INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1582941575110_0025\n",
      "2020-02-29 02:36:22,217 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://7b1cffac5c23:8088/proxy/application_1582941575110_0025/\n",
      "2020-02-29 02:36:42,245 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:36:42,250 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:36:42,300 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:36:42,303 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:36:42,344 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:36:42,346 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:36:42,365 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:36:42,368 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:36:42,389 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:36:42,391 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:36:42,410 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:36:42,412 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:36:42,437 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "(aaa,{(aaa,6),(aaa,0),(aaa,7),(aaa,5),(aaa,3),(aaa,8),(aaa,2),(aaa,3),(aaa,4),(aaa,1),(aaa,2),(aaa,9),(aaa,3)})\n",
      "(bbb,{(bbb,0),(bbb,4),(bbb,8),(bbb,7),(bbb,3),(bbb,7),(bbb,3),(bbb,9),(bbb,6),(bbb,9),(bbb,9),(bbb,7),(bbb,7),(bbb,0),(bbb,2),(bbb,1)})\n",
      "(ccc,{(ccc,3),(ccc,2),(ccc,0),(ccc,1),(ccc,9),(ccc,6),(ccc,1),(ccc,7),(ccc,4),(ccc,3),(ccc,1),(ccc,0),(ccc,1),(ccc,4),(ccc,1),(ccc,5),(ccc,0),(ccc,6),(ccc,6),(ccc,7),(ccc,0),(ccc,5),(ccc,0)})\n",
      "(ddd,{(ddd,2),(ddd,0),(ddd,5),(ddd,7),(ddd,7),(ddd,5),(ddd,5),(ddd,3),(ddd,6),(ddd,2),(ddd,0),(ddd,0),(ddd,9),(ddd,5),(ddd,2),(ddd,9),(ddd,3),(ddd,2),(ddd,9),(ddd,9),(ddd,3),(ddd,5),(ddd,0)})\n",
      "(eee,{(eee,5),(eee,6),(eee,3),(eee,0),(eee,4),(eee,3),(eee,6),(eee,4),(eee,5),(eee,5),(eee,1),(eee,2),(eee,7),(eee,4),(eee,0)})\n",
      "(fff,{(fff,3),(fff,9),(fff,4),(fff,0),(fff,3),(fff,8),(fff,1),(fff,2),(fff,9),(fff,4),(fff,7),(fff,4),(fff,9),(fff,2),(fff,5),(fff,7),(fff,3),(fff,8),(fff,1),(fff,5)})\n",
      "(ggg,{(ggg,8),(ggg,3),(ggg,9),(ggg,6),(ggg,9),(ggg,2),(ggg,0),(ggg,3),(ggg,5),(ggg,8),(ggg,2),(ggg,0),(ggg,6)})\n",
      "(hhh,{(hhh,9),(hhh,2),(hhh,4),(hhh,9),(hhh,1),(hhh,5),(hhh,8),(hhh,1),(hhh,6),(hhh,6),(hhh,9),(hhh,3),(hhh,6),(hhh,0),(hhh,5),(hhh,6)})\n",
      "(iii,{(iii,7),(iii,6),(iii,0),(iii,4),(iii,7),(iii,9),(iii,7),(iii,4),(iii,0),(iii,4),(iii,2),(iii,7),(iii,6),(iii,5),(iii,7),(iii,3),(iii,6),(iii,2)})\n",
      "(jjj,{(jjj,0),(jjj,8),(jjj,1),(jjj,2),(jjj,1),(jjj,3),(jjj,0),(jjj,1),(jjj,2),(jjj,6),(jjj,1),(jjj,7),(jjj,7),(jjj,5),(jjj,6),(jjj,3),(jjj,5),(jjj,9)})\n"
     ]
    }
   ],
   "source": [
    "%%pig\n",
    "-- agrupa los registros que tienen la misma palabra\n",
    "grouped = GROUP words BY word;\n",
    "DUMP grouped;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -- genera una variable que cuenta las ocurrencias por cada grupo\n",
      " wordcount = FOREACH grouped GENERATE group, COUNT(words);\n",
      " DUMP wordcount;\n",
      "2020-02-29 02:36:54,523 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:36:55,029 [JobControl] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:36:55,052 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-02-29 02:36:55,059 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-02-29 02:36:55,092 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-02-29 02:36:55,111 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1582941575110_0026\n",
      "2020-02-29 02:36:55,115 [JobControl] INFO  org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.\n",
      "2020-02-29 02:36:55,339 [JobControl] INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1582941575110_0026\n",
      "2020-02-29 02:36:55,341 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://7b1cffac5c23:8088/proxy/application_1582941575110_0026/\n",
      "2020-02-29 02:37:15,429 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:37:15,435 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:37:15,502 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:37:15,508 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:37:15,538 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:37:15,540 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:37:15,563 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:37:15,565 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:37:15,587 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:37:15,590 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:37:15,610 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:37:15,612 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:37:15,642 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "(aaa,13)\n",
      "(bbb,16)\n",
      "(ccc,23)\n",
      "(ddd,23)\n",
      "(eee,15)\n",
      "(fff,20)\n",
      "(ggg,13)\n",
      "(hhh,16)\n",
      "(iii,18)\n",
      "(jjj,18)\n"
     ]
    }
   ],
   "source": [
    "%%pig\n",
    "-- genera una variable que cuenta las ocurrencias por cada grupo\n",
    "wordcount = FOREACH grouped GENERATE group, COUNT(words);\n",
    "DUMP wordcount;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pig_quit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################\n",
    "########################################################################################################\n",
    "########################################################################################################\n",
    "########################################################################################################\n",
    "########################################################################################################\n",
    "########################################################################################################\n",
    "## Código en Apache Pig\n",
    "##   Nota. Se usan los dos guiones -- para comentario de una línea y /* … */ para comentarios de varias líneas.\n",
    "########################################################################################################\n",
    "########################################################################################################\n",
    "########################################################################################################\n",
    "########################################################################################################\n",
    "########################################################################################################\n",
    "########################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: `input/*': No such file or directory\n",
      "Deleted output/_SUCCESS\n",
      "Deleted output/part-r-00000\n",
      "rmdir: `input': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "## Limpieza del HDFS y de la máquina local\n",
    "## Se crea el directorio de entrada\n",
    "## Se elimina el directorio de salida en el hdfs si existe\n",
    "!hadoop fs -rm input/*\n",
    "!hadoop fs -rm output/*\n",
    "!hadoop fs -rmdir output input\n",
    "## Se elimina la carpeta si existe\n",
    "!rm -rf output input\n",
    "# !mkdir output input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing script.pig\n"
     ]
    }
   ],
   "source": [
    "%%writefile script.pig\n",
    "\n",
    "-- carga de datos\n",
    "lines = LOAD 'data.tsv' AS (clave:CHARARRAY, reg1:BAG{t:(p:CHARARRAY)}, reg2:MAP[]);\n",
    "\n",
    "-- genera una tabla llamada words con una palabra por registro\n",
    "words = FOREACH lines GENERATE FLATTEN(reg2) AS word;\n",
    "\n",
    "-- agrupa los registros que tienen la misma palabra\n",
    "grouped = GROUP words BY word;\n",
    "\n",
    "-- genera una variable que cuenta las ocurrencias por cada grupo\n",
    "wordcount = FOREACH grouped GENERATE group, COUNT(words);\n",
    "\n",
    "-- escribe el archivo de salida\n",
    "STORE wordcount INTO 'output' USING PigStorage(',');\n",
    "\n",
    "-- copia los archivos del HDFS al sistema local\n",
    "fs -get output/ ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-29 02:40:05,462 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2020-02-29 02:40:06,805 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.textoutputformat.separator is deprecated. Instead, use mapreduce.output.textoutputformat.separator\n",
      "2020-02-29 02:40:07,114 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:40:07,286 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2020-02-29 02:40:07,290 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.compress is deprecated. Instead, use mapreduce.output.fileoutputformat.compress\n",
      "2020-02-29 02:40:07,301 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2020-02-29 02:40:07,311 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.submit.replication is deprecated. Instead, use mapreduce.client.submit.file.replication\n",
      "2020-02-29 02:40:07,701 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker.http.address is deprecated. Instead, use mapreduce.jobtracker.http.address\n",
      "2020-02-29 02:40:07,708 [JobControl] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:40:07,732 [JobControl] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
      "2020-02-29 02:40:07,824 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-02-29 02:40:07,851 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-02-29 02:40:07,928 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-02-29 02:40:08,077 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1582941575110_0027\n",
      "2020-02-29 02:40:08,263 [JobControl] INFO  org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.\n",
      "2020-02-29 02:40:08,341 [JobControl] INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1582941575110_0027\n",
      "2020-02-29 02:40:08,375 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://7b1cffac5c23:8088/proxy/application_1582941575110_0027/\n",
      "2020-02-29 02:40:28,504 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:40:28,518 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:40:28,672 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:40:28,681 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:40:28,717 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:40:28,721 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:40:28,788 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:40:28,792 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:40:28,826 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:40:28,830 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:40:28,862 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:40:28,868 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n"
     ]
    }
   ],
   "source": [
    "## Ejecución del script en modo batch\n",
    "!pig -execute 'run script.pig'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aaa,13\n",
      "bbb,16\n",
      "ccc,23\n",
      "ddd,23\n",
      "eee,15\n",
      "fff,20\n",
      "ggg,13\n",
      "hhh,16\n",
      "iii,18\n",
      "jjj,18\n"
     ]
    }
   ],
   "source": [
    "## Visualización de los resultados en el HDFS\n",
    "!hadoop fs -cat output/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aaa,13\n",
      "bbb,16\n",
      "ccc,23\n",
      "ddd,23\n",
      "eee,15\n",
      "fff,20\n",
      "ggg,13\n",
      "hhh,16\n",
      "iii,18\n",
      "jjj,18\n"
     ]
    }
   ],
   "source": [
    "## Visualilzación de resultados en el sistema local\n",
    "!cat output/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
