{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The bigdata extension is already loaded. To reload it, use:\n",
      "  %reload_ext bigdata\n",
      "Found 1 items\n",
      "-rw-r--r--   1 root supergroup       1780 2020-02-29 02:01 data.tsv\n"
     ]
    }
   ],
   "source": [
    "########################################################################################################\n",
    "## Ejecución de Pig en Jupyter\n",
    "##    A continuación se describe como ejecutar comandos de Pig en Jupyter usando la extensión de Jupyter bigdata.\n",
    "%load_ext bigdata\n",
    "%pig_start\n",
    "%timeout 300\n",
    "## WordCount en Apache Pig\n",
    "##   Se cargan los archivos en Apache Pig.\n",
    "!hadoop fs -put *.tsv .\n",
    "!hadoop fs -ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eg2:MAP[]);AD 'data.tsv' AS (clave:CHARARRAY, reg1:BAG{t:(p:CHARARRAY)}, r \n",
      " DUMP lines;\n",
      "2020-02-29 02:03:35,366 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:03:37,106 [JobControl] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:03:37,130 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-02-29 02:03:37,144 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-02-29 02:03:37,992 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-02-29 02:03:38,423 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1582941575110_0003\n",
      "2020-02-29 02:03:38,428 [JobControl] INFO  org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.\n",
      "2020-02-29 02:03:38,467 [JobControl] INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1582941575110_0003\n",
      "2020-02-29 02:03:38,472 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://7b1cffac5c23:8088/proxy/application_1582941575110_0003/\n",
      "2020-02-29 02:03:53,570 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:03:53,575 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:03:53,686 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:03:53,691 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:03:53,725 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:03:53,730 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:03:53,760 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:03:53,774 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:03:53,800 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:03:53,803 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:03:53,829 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:03:53,833 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:03:53,874 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "(E,{(b),(g),(f)},[hhh#2,bbb#0,jjj#3,ddd#9,ggg#8])\n",
      "(A,{(a),(f),(c)},[aaa#3,hhh#9,ccc#2,ddd#0])\n",
      "(B,{(f),(e),(a),(c)},[ccc#6,jjj#1,ddd#2,ggg#5])\n",
      "(A,{(a),(b)},[iii#5,hhh#9,bbb#1,eee#7])\n",
      "(C,{(f),(g),(d),(a)},[iii#6,jjj#3,eee#4,ddd#5])\n",
      "(A,{(c),(d)},[aaa#7,hhh#0,ccc#4,bbb#2,fff#1])\n",
      "(A,{(g),(d),(a)},[aaa#5,iii#0,ccc#1,jjj#7,ddd#2,fff#8])\n",
      "(B,{(b),(a)},[ddd#2,hhh#1,fff#3])\n",
      "(E,{(d),(e),(a),(f)},[iii#9,ccc#5,bbb#0,eee#4,ggg#6,fff#7])\n",
      "(B,{(d),(b),(g),(f)},[iii#4,bbb#7,jjj#9,eee#3,ggg#2,fff#5])\n",
      "(C,{(d),(c),(f),(b)},[iii#0,hhh#6,jjj#1,eee#4,fff#2])\n",
      "(C,{(d),(e),(a),(c)},[iii#6,ggg#9,bbb#7])\n",
      "(D,{(g),(e),(f),(b)},[aaa#3,ccc#6,bbb#9,eee#2,fff#4])\n",
      "(E,{(c),(f)},[aaa#8,ddd#5,jjj#1])\n",
      "(B,{(d),(b)},[aaa#2,ccc#0,jjj#6,ddd#3,fff#7])\n",
      "(D,{(f),(e)},[ccc#0,bbb#9,eee#6,ddd#3])\n",
      "(E,{(e),(b),(f)},[iii#3,hhh#5,bbb#6,ddd#2,ggg#9,fff#4])\n",
      "(D,{(g),(a)},[hhh#4,ccc#9,jjj#5])\n",
      "(E,{(e),(c),(f),(a)},[iii#6,ccc#1,fff#9])\n",
      "(E,{(e),(a)},[aaa#3,bbb#9,fff#1])\n",
      "(E,{(e),(f)},[aaa#4,iii#2,ddd#9])\n",
      "(E,{(c),(b),(g)},[iii#7,ccc#5,fff#8])\n",
      "(D,{(c),(f),(a)},[eee#3,ddd#7,jjj#2])\n",
      "(A,{(f),(a),(d)},[ccc#7,bbb#3,jjj#1,ddd#9,ggg#0])\n",
      "(E,{(c),(d)},[aaa#1,iii#7,hhh#9,ccc#0,jjj#6,ggg#8])\n",
      "(E,{(e),(d),(c)},[iii#4,ccc#1,bbb#7,eee#6,ddd#0,fff#3])\n",
      "(A,{(a),(e),(f)},[ddd#5,ccc#4,fff#0])\n",
      "(E,{(c),(a),(g)},[hhh#3,ccc#0,jjj#7,ddd#9,ggg#6])\n",
      "(A,{(f),(e)},[iii#7,hhh#6,ccc#3,jjj#0,eee#5])\n",
      "(C,{(f),(c),(a),(g)},[aaa#2,ccc#7,eee#1,ddd#6,ggg#0,fff#4])\n",
      "(A,{(b),(f)},[aaa#9,ccc#6,bbb#3,eee#5,ddd#0])\n",
      "(D,{(b),(f)},[aaa#6,iii#4,hhh#1,bbb#7,ddd#5,fff#9])\n",
      "(E,{(a),(c)},[ccc#1,eee#5,ggg#2,fff#3])\n",
      "(B,{(b),(f),(c)},[iii#7,hhh#5,ccc#1,jjj#8,ddd#0,ggg#3])\n",
      "(B,{(f),(a),(e)},[hhh#6,ccc#3,bbb#8,jjj#0,ddd#7])\n",
      "(D,{(a),(f)},[aaa#0,ddd#3,fff#5])\n",
      "(B,{(c),(a)},[iii#7,ccc#0,bbb#4,jjj#2,ddd#5])\n",
      "(C,{(c),(a),(e),(f)},[eee#0,hhh#6,fff#2])\n",
      "(E,{(e),(d)},[eee#0,iii#2,fff#9])\n",
      "(E,{(f),(a),(d)},[hhh#8,ggg#3,jjj#5])\n"
     ]
    }
   ],
   "source": [
    "%%pig\n",
    "lines = LOAD 'data.tsv' AS (clave:CHARARRAY, reg1:BAG{t:(p:CHARARRAY)}, reg2:MAP[]);\n",
    "DUMP lines;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -- genera una tabla llamada words con una palabra por registro\n",
      " words = FOREACH lines GENERATE FLATTEN(reg1) AS word;\n",
      " DUMP words;\n",
      "2020-02-29 02:13:20,200 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:13:21,505 [JobControl] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:13:21,521 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-02-29 02:13:21,530 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-02-29 02:13:22,362 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-02-29 02:13:22,789 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1582941575110_0006\n",
      "2020-02-29 02:13:22,792 [JobControl] INFO  org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.\n",
      "2020-02-29 02:13:22,819 [JobControl] INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1582941575110_0006\n",
      "2020-02-29 02:13:22,825 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://7b1cffac5c23:8088/proxy/application_1582941575110_0006/\n",
      "2020-02-29 02:13:37,934 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:13:37,938 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:13:38,024 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:13:38,028 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:13:38,050 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:13:38,054 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:13:38,078 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:13:38,083 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:13:38,110 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:13:38,113 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:13:38,134 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:13:38,137 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:13:38,169 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "(b)\n",
      "(g)\n",
      "(f)\n",
      "(a)\n",
      "(f)\n",
      "(c)\n",
      "(f)\n",
      "(e)\n",
      "(a)\n",
      "(c)\n",
      "(a)\n",
      "(b)\n",
      "(f)\n",
      "(g)\n",
      "(d)\n",
      "(a)\n",
      "(c)\n",
      "(d)\n",
      "(g)\n",
      "(d)\n",
      "(a)\n",
      "(b)\n",
      "(a)\n",
      "(d)\n",
      "(e)\n",
      "(a)\n",
      "(f)\n",
      "(d)\n",
      "(b)\n",
      "(g)\n",
      "(f)\n",
      "(d)\n",
      "(c)\n",
      "(f)\n",
      "(b)\n",
      "(d)\n",
      "(e)\n",
      "(a)\n",
      "(c)\n",
      "(g)\n",
      "(e)\n",
      "(f)\n",
      "(b)\n",
      "(c)\n",
      "(f)\n",
      "(d)\n",
      "(b)\n",
      "(f)\n",
      "(e)\n",
      "(e)\n",
      "(b)\n",
      "(f)\n",
      "(g)\n",
      "(a)\n",
      "(e)\n",
      "(c)\n",
      "(f)\n",
      "(a)\n",
      "(e)\n",
      "(a)\n",
      "(e)\n",
      "(f)\n",
      "(c)\n",
      "(b)\n",
      "(g)\n",
      "(c)\n",
      "(f)\n",
      "(a)\n",
      "(f)\n",
      "(a)\n",
      "(d)\n",
      "(c)\n",
      "(d)\n",
      "(e)\n",
      "(d)\n",
      "(c)\n",
      "(a)\n",
      "(e)\n",
      "(f)\n",
      "(c)\n",
      "(a)\n",
      "(g)\n",
      "(f)\n",
      "(e)\n",
      "(f)\n",
      "(c)\n",
      "(a)\n",
      "(g)\n",
      "(b)\n",
      "(f)\n",
      "(b)\n",
      "(f)\n",
      "(a)\n",
      "(c)\n",
      "(b)\n",
      "(f)\n",
      "(c)\n",
      "(f)\n",
      "(a)\n",
      "(e)\n",
      "(a)\n",
      "(f)\n",
      "(c)\n",
      "(a)\n",
      "(c)\n",
      "(a)\n",
      "(e)\n",
      "(f)\n",
      "(e)\n",
      "(d)\n",
      "(f)\n",
      "(a)\n",
      "(d)\n"
     ]
    }
   ],
   "source": [
    "%%pig\n",
    "-- genera una tabla llamada words con una palabra por registro\n",
    "words = FOREACH lines GENERATE FLATTEN(reg1) AS word;\n",
    "DUMP words;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -- agrupa los registros que tienen la misma palabra\n",
      " grouped = GROUP words BY word;\n",
      " DUMP grouped;\n",
      "2020-02-29 02:13:58,998 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:14:00,717 [JobControl] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:14:00,738 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-02-29 02:14:00,749 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-02-29 02:14:01,189 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-02-29 02:14:01,623 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1582941575110_0007\n",
      "2020-02-29 02:14:01,626 [JobControl] INFO  org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.\n",
      "2020-02-29 02:14:01,658 [JobControl] INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1582941575110_0007\n",
      "2020-02-29 02:14:01,662 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://7b1cffac5c23:8088/proxy/application_1582941575110_0007/\n",
      "2020-02-29 02:14:21,829 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:14:21,836 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:14:21,905 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:14:21,909 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:14:21,937 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:14:21,940 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:14:21,964 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:14:21,967 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:14:21,990 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:14:21,992 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:14:22,014 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:14:22,017 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:14:22,046 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "(a,{(a),(a),(a),(a),(a),(a),(a),(a),(a),(a),(a),(a),(a),(a),(a),(a),(a),(a),(a),(a),(a),(a)})\n",
      "(b,{(b),(b),(b),(b),(b),(b),(b),(b),(b),(b),(b),(b)})\n",
      "(c,{(c),(c),(c),(c),(c),(c),(c),(c),(c),(c),(c),(c),(c),(c),(c),(c),(c)})\n",
      "(d,{(d),(d),(d),(d),(d),(d),(d),(d),(d),(d),(d),(d),(d)})\n",
      "(e,{(e),(e),(e),(e),(e),(e),(e),(e),(e),(e),(e),(e),(e),(e),(e)})\n",
      "(f,{(f),(f),(f),(f),(f),(f),(f),(f),(f),(f),(f),(f),(f),(f),(f),(f),(f),(f),(f),(f),(f),(f),(f),(f),(f)})\n",
      "(g,{(g),(g),(g),(g),(g),(g),(g),(g),(g)})\n"
     ]
    }
   ],
   "source": [
    "%%pig\n",
    "-- agrupa los registros que tienen la misma palabra\n",
    "grouped = GROUP words BY word;\n",
    "DUMP grouped;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -- genera una variable que cuenta las ocurrencias por cada grupo\n",
      " wordcount = FOREACH grouped GENERATE group, COUNT(words);\n",
      " DUMP wordcount;\n",
      "2020-02-29 02:14:36,725 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:14:37,671 [JobControl] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:14:37,696 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-02-29 02:14:37,704 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-02-29 02:14:38,548 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-02-29 02:14:38,586 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1582941575110_0008\n",
      "2020-02-29 02:14:38,589 [JobControl] INFO  org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.\n",
      "2020-02-29 02:14:38,825 [JobControl] INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1582941575110_0008\n",
      "2020-02-29 02:14:38,828 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://7b1cffac5c23:8088/proxy/application_1582941575110_0008/\n",
      "2020-02-29 02:14:58,938 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:14:58,946 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:14:59,015 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:14:59,019 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:14:59,044 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:14:59,047 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:14:59,084 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:14:59,087 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:14:59,135 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:14:59,141 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:14:59,183 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:14:59,187 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:14:59,219 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "(a,22)\n",
      "(b,12)\n",
      "(c,17)\n",
      "(d,13)\n",
      "(e,15)\n",
      "(f,25)\n",
      "(g,9)\n"
     ]
    }
   ],
   "source": [
    "%%pig\n",
    "-- genera una variable que cuenta las ocurrencias por cada grupo\n",
    "wordcount = FOREACH grouped GENERATE group, COUNT(words);\n",
    "DUMP wordcount;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pig_quit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################\n",
    "########################################################################################################\n",
    "########################################################################################################\n",
    "########################################################################################################\n",
    "########################################################################################################\n",
    "########################################################################################################\n",
    "## Código en Apache Pig\n",
    "##   Nota. Se usan los dos guiones -- para comentario de una línea y /* … */ para comentarios de varias líneas.\n",
    "########################################################################################################\n",
    "########################################################################################################\n",
    "########################################################################################################\n",
    "########################################################################################################\n",
    "########################################################################################################\n",
    "########################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: `input/*': No such file or directory\n",
      "rm: `output/*': No such file or directory\n",
      "rmdir: `output': No such file or directory\n",
      "rmdir: `input': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "## Limpieza del HDFS y de la máquina local\n",
    "## Se crea el directorio de entrada\n",
    "## Se elimina el directorio de salida en el hdfs si existe\n",
    "!hadoop fs -rm input/*\n",
    "!hadoop fs -rm output/*\n",
    "!hadoop fs -rmdir output input\n",
    "## Se elimina la carpeta si existe\n",
    "!rm -rf output input\n",
    "# !mkdir output input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing script.pig\n"
     ]
    }
   ],
   "source": [
    "%%writefile script.pig\n",
    "\n",
    "-- carga de datos\n",
    "lines = LOAD 'data.tsv' AS (clave:CHARARRAY, reg1:BAG{t:(p:CHARARRAY)}, reg2:MAP[]);\n",
    "\n",
    "-- genera una tabla llamada words con una palabra por registro\n",
    "words = FOREACH lines GENERATE FLATTEN(reg1) AS word;\n",
    "\n",
    "-- agrupa los registros que tienen la misma palabra\n",
    "grouped = GROUP words BY word;\n",
    "\n",
    "-- genera una variable que cuenta las ocurrencias por cada grupo\n",
    "wordcount = FOREACH grouped GENERATE group, COUNT(words);\n",
    "\n",
    "-- escribe el archivo de salida\n",
    "STORE wordcount INTO 'output';\n",
    "\n",
    "-- copia los archivos del HDFS al sistema local\n",
    "fs -get output/ ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-29 02:17:50,535 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2020-02-29 02:17:51,874 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.textoutputformat.separator is deprecated. Instead, use mapreduce.output.textoutputformat.separator\n",
      "2020-02-29 02:17:52,186 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:17:52,356 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2020-02-29 02:17:52,360 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.compress is deprecated. Instead, use mapreduce.output.fileoutputformat.compress\n",
      "2020-02-29 02:17:52,371 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2020-02-29 02:17:52,384 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.submit.replication is deprecated. Instead, use mapreduce.client.submit.file.replication\n",
      "2020-02-29 02:17:53,176 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker.http.address is deprecated. Instead, use mapreduce.jobtracker.http.address\n",
      "2020-02-29 02:17:53,183 [JobControl] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:17:53,207 [JobControl] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
      "2020-02-29 02:17:53,301 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-02-29 02:17:53,356 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-02-29 02:17:53,521 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-02-29 02:17:53,662 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1582941575110_0009\n",
      "2020-02-29 02:17:53,852 [JobControl] INFO  org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.\n",
      "2020-02-29 02:17:54,436 [JobControl] INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1582941575110_0009\n",
      "2020-02-29 02:17:54,474 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://7b1cffac5c23:8088/proxy/application_1582941575110_0009/\n",
      "2020-02-29 02:18:14,624 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:18:14,631 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:18:14,804 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:18:14,811 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:18:14,855 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:18:14,864 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:18:14,939 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:18:14,947 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:18:14,990 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:18:14,995 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-29 02:18:15,030 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-29 02:18:15,036 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n"
     ]
    }
   ],
   "source": [
    "## Ejecución del script en modo batch\n",
    "!pig -execute 'run script.pig'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\t22\n",
      "b\t12\n",
      "c\t17\n",
      "d\t13\n",
      "e\t15\n",
      "f\t25\n",
      "g\t9\n"
     ]
    }
   ],
   "source": [
    "## Visualización de los resultados en el HDFS\n",
    "!hadoop fs -cat output/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\t22\n",
      "b\t12\n",
      "c\t17\n",
      "d\t13\n",
      "e\t15\n",
      "f\t25\n",
      "g\t9\n"
     ]
    }
   ],
   "source": [
    "## Visualilzación de resultados en el sistema local\n",
    "!cat output/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
